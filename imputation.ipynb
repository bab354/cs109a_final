{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CS109 A (Group 18) - Blake Barr | Lekshmi Santhosh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.read_json(\"output/final_only11.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first decided that a variable needed to be there **> 75%** of the time for us to impute it. The threshold of 75% or greater was set to obtain realistic, reliable and complete imputations. Heursitics and the findings from EDA drove the design of our imputation strategy. We thought that the best way to impute data is to use **a simple linear interpolation by MSA**. This approach attempts to take advantage of the fact that a variable should be highly related to itself in the past and future within the MSA.\n",
    "\n",
    "We designed two approaches and evaluated the efficacy using the downstream performance -\n",
    "\n",
    "### Approach 1\n",
    "\n",
    "This equation is what will be used to impute a variable denoted Y<sub>t</sub> for year t\n",
    "\n",
    " $$Y_t = B_0 + B_1 Y_{t-1} + B_2 \\frac{Pop_t}{Pop_{t-1}} + B_3 MSA_i $$\n",
    " \n",
    "We will leverage the variable value from the previous year (if available) and iteratively fill Yt until the variable is completely filled. For example - Consider a situation where a variable has missing values for both 2008 and 2009. We first predict the variable value for 2008 using 2007. The imputed value of 2008 is then used to estimate the missing value of 2009.\n",
    "\n",
    "If the variable has missing values for all past years before year t, the abovesaid strategy wonâ€™t work. In such instances, we use the observation for future years (i.e. the years after t ) for imputation.\n",
    "\n",
    "\n",
    " $$Y_t = Y_{t+1} * \\frac{Pop_t}{Pop_{t+1}} $$\n",
    " \n",
    "### Approach 2\n",
    "\n",
    " \n",
    " $$Y_t = Y_{t-n/t+n} * \\frac{Pop_t}{Pop_{t-n/t+n}} $$\n",
    "\n",
    "In this second approach, we will do simple population adjustment using the nearest available year. Here, n represents the number of missing periods we have to go to find the first non-missing data. First, we will go to first lag period (one year before). If that is missing, we will go to year after. If data is missing for the nearest years (both lag and lead), we then identify two years before the year in question. If that is missing, we attempt an interpolation using the two years after, etc.\n",
    "\n",
    "### Imputation of Carson City Data\n",
    "Carson City MSA had no crime data for the largest city in its MSA. But, since Carson city MSA is just Carson city, we used the MSA wide variables as its city-wide crime variables. Additionally, it was missing unemployment data, so we just grabbed annual unemployment data from the Bureau of Labor Statistics and filled the missings with those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### SET IMPUTATION STRATEGY HERE\n",
    "# This variable serves as a toggle to switch between the two imputation approaches\n",
    "imputation_strategy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.sort_values(['join_key', 'year'])#### Generating Population Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get List of Missing Variables\n",
    "miss_vars = []\n",
    "for v in final_df.columns:\n",
    "    miss_pct =  np.sum(final_df[v].isnull()) / final_df.shape[0]\n",
    "    if miss_pct > 0 and miss_pct < 0.25 and v not in ['largest_city']:\n",
    "        miss_vars.append(v)\n",
    "    if miss_pct > 0.25:\n",
    "          del final_df[v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Population Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    2110\n",
      "NaN      211\n",
      "Name: lag_year_diff, dtype: int64\n",
      "-1.0    2110\n",
      "NaN      211\n",
      "Name: lead_year_diff, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get Population Rate Change\n",
    "# Generate lag given varname and number of periods\n",
    "gen_lags = lambda var, num: final_df.groupby(['join_key'])[var].shift(num)\n",
    "#  Get Lag Year Difference\n",
    "final_df = final_df.sort_values(['join_key', 'year'])\n",
    "final_df['lag_year_diff'] = final_df.year -  gen_lags('year', 1)\n",
    "print(final_df['lag_year_diff'].value_counts(dropna=False))\n",
    "# Get Lag Population\n",
    "final_df['lag1_pop_change' ] = final_df['msa_pop'] / gen_lags('msa_pop', 1)\n",
    "\n",
    "# Get Lead Year Difference\n",
    "final_df['lead_year_diff'] = final_df.year - gen_lags('year', -1)\n",
    "print(final_df['lead_year_diff'].value_counts(dropna=False))\n",
    "# Lead 1 Population\n",
    "final_df['lead1_pop_change' ] = final_df['msa_pop'] / gen_lags('msa_pop', -1)\n",
    "\n",
    "del final_df['lead_year_diff']\n",
    "del final_df['lag_year_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation Strategy # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Strategy 1\n"
     ]
    }
   ],
   "source": [
    "if imputation_strategy == 1:\n",
    "    print(\"Executing Strategy 1\")\n",
    "    # Imputation Approach # 1\n",
    "    for v in miss_vars:\n",
    "        lag_v = 'lag_%s' %v  \n",
    "        ############################################\n",
    "        # While current variable has missing value\n",
    "        ############################################\n",
    "        # Using a counter so it does not go infinite loop\n",
    "        # If missing all 11 values, won't be able to impute\n",
    "        i = 0\n",
    "        while np.sum(final_df.loc[:, v].isnull()) > 0:\n",
    "            # Grab previous period value (either year before or two years)\n",
    "            final_df[lag_v] = gen_lags(v, 1)\n",
    "            # Using Lag variable and MSA FE\n",
    "            x_vars = [v for v in final_df.columns if 'MSA_' in v] +  [lag_v]\n",
    "\n",
    "            # train - lag not missing v not missing\n",
    "            # test - lag not missing. v missing\n",
    "            lag_notnull = final_df[lag_v].notnull()\n",
    "            train = (final_df[v].notnull()) & (lag_notnull)\n",
    "            test = (final_df[v].isnull()) & (lag_notnull)\n",
    "\n",
    "            # If there are situations where v is missing\n",
    "            # but lag is also missing for all. We cannot do anything\n",
    "            # we will have to use future data\n",
    "            if np.sum(test) == 0 or i == 11:\n",
    "                break\n",
    "            # Only have to run regression once - \n",
    "            # Then iteratively fill using coefficeints\n",
    "            if i == 0:\n",
    "                lin_reg = LinearRegression().fit(final_df.loc[train, x_vars], \n",
    "                                                 final_df.loc[train, v])\n",
    "\n",
    "            i = i + 1\n",
    "            # Fill in missing data with predictions\n",
    "            final_df.loc[test, v] = lin_reg.predict(final_df.loc[test, x_vars])\n",
    "        # Get rid of lag var if you created one\n",
    "        if lag_v in final_df.columns:\n",
    "            del final_df[lag_v]\n",
    "        ##################################\n",
    "        # Still Missing - Use Future Data\n",
    "        ##################################\n",
    "        # Similiar counter. \n",
    "        # Do not get stuck in infinite loop if all future also missing\n",
    "        j = 0\n",
    "        while np.sum(final_df.loc[:, v].isnull()) > 0:\n",
    "            if j == 11:\n",
    "                break\n",
    "            lead_v = 'lead_%s' %v \n",
    "            # Get future Value\n",
    "            final_df[lead_v] = gen_lags(v, -1)\n",
    "            # Need v to be missing and v in next period to be next missing\n",
    "            null_v = (final_df[v].isnull()) & (final_df[lead_v].notnull())\n",
    "            # Yt= Yt+1 * (Pt/Pt+1)\n",
    "            final_df.loc[null_v, v] = final_df.loc[null_v, \n",
    "                                                   lead_v] * final_df.loc[null_v, \n",
    "                                                                          \"lead1_pop_change\"]\n",
    "            j = j + 1\n",
    "            del final_df[lead_v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Strategy # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function\n",
    "---------\n",
    "adjust_var\n",
    "\n",
    "Given lag/lead and period This function will return the variable in that lag/lead\n",
    "period times population change between current period and that period\n",
    "'''\n",
    "def adjust_var(df, var, period_num, lead=False):\n",
    "    if lead:\n",
    "        period_num = -1 * period_num\n",
    "    shift_var = \"shift_%s\" %var\n",
    "    df.loc[:, shift_var] = gen_lags(var, period_num)\n",
    "    df.loc[:, 'shift_pop'] = df['msa_pop'] / gen_lags('msa_pop', period_num)\n",
    "    miss  = df[var].isnull()\n",
    "    # Fill missing with adjustment\n",
    "    df.loc[miss, v] = df.loc[miss, shift_var] * df.loc[miss, 'shift_pop']\n",
    "    del df[shift_var]\n",
    "    del df['shift_pop']\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if imputation_strategy == 2:\n",
    "    print(\"Executing Strategy # 2\")\n",
    "    # This we will juse use lead and lag value with population adjustment\n",
    "    get_missing = lambda v: np.sum(final_df.loc[:, v].isnull())\n",
    "    # Switch off lag, lead, lag, lead\n",
    "    for v in miss_vars:\n",
    "        if get_missing(v) > 0:\n",
    "            for period in range(1, 11):\n",
    "                # Do Lags and then lead for each period\n",
    "                for lead_bool in [False, True]:\n",
    "                    final_df = adjust_var(final_df, v, period, lead=lead_bool)\n",
    "                if get_missing(v) == 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation for Carson City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carson city was missing city crime statistics. Since this MSA just includes Carson city we decided to use the MSA wide crime stats as the city stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carson = final_df.city_key.str.contains(\"Carson\")\n",
    "final_df.loc[carson, ['MSA', 'year']].head(13)\n",
    "crime_vars = ['violent_crime','mur_mans', 'rape', 'robbery',\n",
    "             'assault', 'property', 'burglary', 'larceny','mv_theft']\n",
    "for v in crime_vars:\n",
    "    final_df.loc[carson, 'city_%s' %v] = final_df.loc[carson, v]\n",
    "# Fix population\n",
    "final_df.loc[carson, 'city_pop'] = final_df.loc[carson,'msa_pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del final_df['lead1_pop_change']\n",
    "del final_df['lag1_pop_change']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still missing Carson City unemployment data. Going to use unemployment data from BLS to fill these in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Going to just use annual Carson City unemployment data for\n",
    "# 3 unemployment vars missing for carson cityall variables\n",
    "carson_labor = pd.read_excel(\"data/NVCARS0URN.xls\", skiprows=10)\n",
    "carson_labor['year'] = carson_labor[\"observation_date\"].dt.year\n",
    "carson_labor = carson_labor.loc[(carson_labor.year >= 2006) & \n",
    "                                (carson_labor.year <= 2016), :]\n",
    "annual_stats = list(carson_labor.groupby(\"year\")['NVCARS0URN'].mean())\n",
    "\n",
    "# Fill in Carson City Crime Stats using Annual Stats\n",
    "for i, year in enumerate(range(2006, 2017)):\n",
    "    final_df.loc[(final_df['join_key'] == 'Carson City-NV') & \n",
    "                 (final_df.year == year), \n",
    "                 ['unemp_16_19', 'unemp_16_ovr', 'unemp_female']] = annual_stats[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest_city\n",
      "MSAs\n",
      "['Carson City-NV' 'Texarkana-AR-TX']\n"
     ]
    }
   ],
   "source": [
    "# Check for remaining missing\n",
    "for v in final_df.columns:\n",
    "    if \"MSA_\" not in v:\n",
    "        miss_pct =  np.sum(final_df[v].isnull()) / final_df.shape[0]\n",
    "        if miss_pct > 0:\n",
    "            print(v)\n",
    "            print(\"MSAs\")\n",
    "            print(final_df.loc[final_df[v].isnull(),'join_key'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save version based on imputation variables\n",
    "final_df.to_json('output/final_imputed%i.json' %imputation_strategy)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
