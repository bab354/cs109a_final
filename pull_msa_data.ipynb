{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will pull other data that we plan to use for the CS 109 final projects. Planning on bringing in education, demographic, and economic data to help us predict crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "---------------\n",
    "split_MSA\n",
    "\n",
    "This method takes in a dataframe with MSA and splits into a city_key (largest city)\n",
    "and state_key. This will help facilitate MSA merging\n",
    "\n",
    "Returns dataframe with these two additional features\n",
    "\"\"\"\n",
    "def split_MSA(df):\n",
    "    df['MSA'] = df['MSA'].str.replace('Metro Area', '')\n",
    "    # Need to manually fix how this MSA is written\n",
    "    df.loc[df['MSA'].str.contains(\"Texarkana\"), \"MSA\"] = \"Texarkana, AR-TX\"\n",
    "\n",
    "    #Grab Everything before comma\n",
    "    df['city_key'] = df['MSA'].str.split(\",\").str[0]\n",
    "    # Then grab everything before first hyphen if it has it\n",
    "    df['city_key'] = df['city_key'].str.split(\"-\").str[0].str.strip()\n",
    "    # State will be everying after comma \n",
    "    df['state_key']=df['MSA'].str.split(\",\").str[1].str.strip()\n",
    "    return(df)\n",
    "\n",
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "append_df\n",
    "\n",
    "This function appends two dataframes\n",
    "\n",
    "Parameters:\n",
    "    input - dataframe to be appended\n",
    "    output - dataframe to be appended onto\n",
    "    \n",
    "Returns a single dataframe \n",
    "\"\"\"\n",
    "def append_df(input,output):\n",
    "    if output.empty:\n",
    "        output=input.copy()\n",
    "    else:\n",
    "        output=pd.concat([output,input])\n",
    "        output.reset_index(drop='Index',inplace=True)\n",
    "    return(output)\n",
    "\n",
    "'''\n",
    "Function\n",
    "-----------\n",
    "var_thresh\n",
    "\n",
    "This function takes in a dataframe and keeps only thos varaibles that have a pct\n",
    "non-missing that is above that threshold\n",
    "'''\n",
    "def var_thresh(df, thresh=0.65):\n",
    "    return(df.loc[:, pd.notnull(df).sum() > len (df) *thresh])\n",
    "\n",
    "'''\n",
    "Function\n",
    "---------\n",
    "slim_df\n",
    "\n",
    "This function takes in a list of variables to keep\n",
    "on the the given df. It keep the variables + geography\n",
    "then renames to MSA and drops the first row of variable descriptions\n",
    "'''\n",
    "def slim_df(df, var_list):\n",
    "    var_list.append('GEO.display-label')\n",
    "    df = df.loc[:, var_list]\n",
    "    df = df.rename(index=str, columns={'GEO.display-label': 'MSA'})\n",
    "    df['MSA'] = df[\"MSA\"].astype(str)\n",
    "    # Drop first row of var descriptions\n",
    "    df = df.loc[df.MSA != \"Geography\", :]\n",
    "    # Split MSA into city-state key\n",
    "    return(split_MSA(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function\n",
    "---------\n",
    "match_crime\n",
    "\n",
    "This function will take in a dataframe and make changes to MSA\n",
    "in order to match crime data\n",
    "'''\n",
    "def match_crime(df):\n",
    "    df.loc[df['MSA'].str.contains('Crestview'),'city_key']='Crestview'\n",
    "    df.loc[df['MSA'].str.contains('Sarasota'),'city_key']='North Port'\n",
    "    df.loc[df['MSA'].str.contains('Louisville'),'city_key']='Louisville'\n",
    "    df.loc[df['MSA'].str.contains('Santa Maria'),'city_key']='Santa Maria'\n",
    "    df.loc[df['MSA'].str.contains('Weirton'),'city_key']='Weirton'\n",
    "    df.loc[df['MSA'].str.contains('San Germán'),'city_key']='San German'\n",
    "    df.loc[df['MSA'].str.contains('Mayagüez'),'city_key']='Mayaguez'\n",
    "    df.loc[df['MSA'].str.contains('Honolulu'),'city_key']='Urban Honolulu'\n",
    "\n",
    "    #State\n",
    "    df.loc[df['MSA'].str.contains('Worcester'),'state_key']='MA-CT'\n",
    "    df.loc[df['MSA'].str.contains('Myrtle Beach'),'state_key']='SC-NC'\n",
    "    df.loc[df['MSA'].str.contains('Salisbury'),'state_key']='MD-DE'\n",
    "    df.loc[df['MSA'].str.contains('Weirton'),'state_key']='WV-OH'\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>unemp_16_ovr</th>\n",
       "      <th>unemp_16_19</th>\n",
       "      <th>unemp_female</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>2.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>5.7</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>8.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city_key state_key unemp_16_ovr unemp_16_19 unemp_female  year\n",
       "0     Abilene        TX          6.6        23.1          5.2  2006\n",
       "367   Abilene        TX          3.2         7.0          3.8  2007\n",
       "736   Abilene        TX          2.8        14.2          1.8  2008\n",
       "1105  Abilene        TX          5.7        22.6          4.8  2009\n",
       "1479  Abilene        TX          8.5        19.9          7.7  2010"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# Employment Data\n",
    "#####################\n",
    "emp_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    if year == 2006:\n",
    "        f = 'ACS_06_EST_S2301'\n",
    "    else:\n",
    "        f = 'ACS_' + str(year)[2:] + '_1YR_S2301'\n",
    "    employ = pd.read_csv(\"data/employ/%s.csv\" %f, encoding='Latin-1')\n",
    "    \n",
    "    # Grab Unemployment\n",
    "    un = [v for v in employ.columns if \"HC04\" in v and \"EST\" in v]\n",
    "    employ = slim_df(employ, un)\n",
    "    \n",
    "    employ = employ.loc[:, [\"MSA\", \"city_key\", \"state_key\", \n",
    "                          \"HC04_EST_VC01\", \"HC04_EST_VC03\",\n",
    "                         'HC04_EST_VC24']]\n",
    "    employ['year'] = year\n",
    "    emp_all = append_df(employ, emp_all) \n",
    "\n",
    "# Process Final DataFrame\n",
    "emp_all = emp_all.sort_values(['city_key', 'state_key', 'year'])\n",
    "emp_all = match_crime(emp_all)\n",
    "del emp_all['MSA']\n",
    "emp_all = emp_all.rename(index=str,\n",
    "                        columns={'HC04_EST_VC01': 'unemp_16_ovr',\n",
    "                                'HC04_EST_VC03': 'unemp_16_19',\n",
    "                                'HC04_EST_VC24': 'unemp_female'})\n",
    "emp_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>median_age</th>\n",
       "      <th>sex_ratio</th>\n",
       "      <th>male_pop</th>\n",
       "      <th>female_pop</th>\n",
       "      <th>pop_15_19</th>\n",
       "      <th>pop_20_24</th>\n",
       "      <th>male_pop_20_24</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>34.4</td>\n",
       "      <td>99.1</td>\n",
       "      <td>0.497717</td>\n",
       "      <td>0.502283</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>34.9</td>\n",
       "      <td>99.1</td>\n",
       "      <td>0.497777</td>\n",
       "      <td>0.502223</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>34.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.502381</td>\n",
       "      <td>0.497619</td>\n",
       "      <td>9.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>33.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.492269</td>\n",
       "      <td>0.507731</td>\n",
       "      <td>7.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501355</td>\n",
       "      <td>0.498645</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city_key state_key median_age sex_ratio  male_pop  female_pop pop_15_19  \\\n",
       "0     Abilene        TX       34.4      99.1  0.497717    0.502283       8.3   \n",
       "367   Abilene        TX       34.9      99.1  0.497777    0.502223       9.5   \n",
       "736   Abilene        TX       34.6     101.0  0.502381    0.497619       9.2   \n",
       "1105  Abilene        TX       33.2      97.0  0.492269    0.507731       7.9   \n",
       "1479  Abilene        TX        NaN       NaN  0.501355    0.498645       7.3   \n",
       "\n",
       "     pop_20_24 male_pop_20_24  year  \n",
       "0          8.7           10.2  2006  \n",
       "367        7.7            8.6  2007  \n",
       "736        7.6            8.9  2008  \n",
       "1105       9.0            9.6  2009  \n",
       "1479       9.5            9.9  2010  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Age Data\n",
    "############\n",
    "age_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    if year == 2006:\n",
    "        f = 'ACS_06_EST_S0101'\n",
    "    else:\n",
    "        f = 'ACS_' + str(year)[2:] + '_1YR_S0101'\n",
    "    age = pd.read_csv(\"data/age/%s.csv\" %f, encoding='Latin-1')\n",
    "    age = slim_df(age, [v for v in age.columns if \"EST\" in v])\n",
    "    age = age.replace(\"(X)\", np.nan)\n",
    "\n",
    "    age = age.loc[:, ['MSA','city_key','state_key',\n",
    "                      'HC01_EST_VC33','HC01_EST_VC34',\n",
    "                      'HC01_EST_VC01', 'HC02_EST_VC01',\n",
    "                      'HC03_EST_VC01', 'HC01_EST_VC06',\n",
    "                      'HC01_EST_VC07', 'HC02_EST_VC07']]\n",
    "    age['year'] = year\n",
    "    age_all = append_df(age, age_all) \n",
    "\n",
    "\n",
    "# Process Final DataFrame\n",
    "age_all = age_all.sort_values(['city_key', 'state_key', 'year'])\n",
    "age_all = age_all.rename(index=str,\n",
    "                         columns={'HC01_EST_VC33':'median_age',\n",
    "                                'HC01_EST_VC34': 'sex_ratio',\n",
    "                                'HC01_EST_VC01': 'total_pop',\n",
    "                                'HC02_EST_VC01': 'male_pop',\n",
    "                                'HC03_EST_VC01': 'female_pop',\n",
    "                                'HC01_EST_VC06': 'pop_15_19',\n",
    "                                'HC01_EST_VC07': 'pop_20_24',\n",
    "                                'HC02_EST_VC07': 'male_pop_20_24'})\n",
    "\n",
    "# Convert to Int and Get Proportions\n",
    "age_all[['total_pop', 'male_pop', 'female_pop']] = age_all[['total_pop', 'male_pop', 'female_pop']].astype(int)\n",
    "age_all['male_pop'] = age_all['male_pop'] / age_all['total_pop']\n",
    "age_all['female_pop'] = age_all['female_pop'] / age_all['total_pop']\n",
    "del age_all['total_pop']\n",
    "# Match Crime Data and then get rid of MSA\n",
    "age_all = match_crime(age_all)\n",
    "del age_all['MSA']\n",
    "age_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_lt10</th>\n",
       "      <th>inc_10_15</th>\n",
       "      <th>inc_15_19</th>\n",
       "      <th>inc_20_24</th>\n",
       "      <th>inc_25_29</th>\n",
       "      <th>inc_30_34</th>\n",
       "      <th>inc_35_39</th>\n",
       "      <th>inc_40_44</th>\n",
       "      <th>inc_45_49</th>\n",
       "      <th>inc_50_59</th>\n",
       "      <th>inc_60_74</th>\n",
       "      <th>inc_75_99</th>\n",
       "      <th>inc_100_124</th>\n",
       "      <th>inc_125_149</th>\n",
       "      <th>inc_150_199</th>\n",
       "      <th>inc_gt_200</th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066006</td>\n",
       "      <td>0.039355</td>\n",
       "      <td>0.191044</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.034552</td>\n",
       "      <td>0.051751</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.044159</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.138829</td>\n",
       "      <td>0.060738</td>\n",
       "      <td>0.099628</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042883</td>\n",
       "      <td>0.102766</td>\n",
       "      <td>0.078153</td>\n",
       "      <td>0.191829</td>\n",
       "      <td>0.056077</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.136514</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.071048</td>\n",
       "      <td>0.108094</td>\n",
       "      <td>0.062928</td>\n",
       "      <td>0.046435</td>\n",
       "      <td>0.025121</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111215</td>\n",
       "      <td>0.064565</td>\n",
       "      <td>0.078066</td>\n",
       "      <td>0.069276</td>\n",
       "      <td>0.056352</td>\n",
       "      <td>0.080003</td>\n",
       "      <td>0.071902</td>\n",
       "      <td>0.061101</td>\n",
       "      <td>0.054006</td>\n",
       "      <td>0.094082</td>\n",
       "      <td>0.101140</td>\n",
       "      <td>0.101661</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.150833</td>\n",
       "      <td>0.063611</td>\n",
       "      <td>0.084792</td>\n",
       "      <td>0.084514</td>\n",
       "      <td>0.105903</td>\n",
       "      <td>0.057778</td>\n",
       "      <td>0.043542</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.080417</td>\n",
       "      <td>0.095417</td>\n",
       "      <td>0.075556</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.042639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>PA-NJ</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084392</td>\n",
       "      <td>0.086299</td>\n",
       "      <td>0.077275</td>\n",
       "      <td>0.135104</td>\n",
       "      <td>0.043213</td>\n",
       "      <td>0.134596</td>\n",
       "      <td>0.061642</td>\n",
       "      <td>0.051856</td>\n",
       "      <td>0.037239</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.054270</td>\n",
       "      <td>0.070285</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.022496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>Amarillo</td>\n",
       "      <td>TX</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inc_lt10  inc_10_15  inc_15_19  inc_20_24  inc_25_29  inc_30_34  inc_35_39  \\\n",
       "0  0.066006   0.039355   0.191044   0.142857   0.034552   0.051751   0.094980   \n",
       "1  0.042883   0.102766   0.078153   0.191829   0.056077   0.063436   0.136514   \n",
       "2  0.111215   0.064565   0.078066   0.069276   0.056352   0.080003   0.071902   \n",
       "3  0.150833   0.063611   0.084792   0.084514   0.105903   0.057778   0.043542   \n",
       "4  0.084392   0.086299   0.077275   0.135104   0.043213   0.134596   0.061642   \n",
       "\n",
       "   inc_40_44  inc_45_49  inc_50_59  inc_60_74  inc_75_99  inc_100_124  \\\n",
       "0   0.044159   0.004803   0.138829   0.060738   0.099628     0.004029   \n",
       "1   0.011165   0.071048   0.108094   0.062928   0.046435     0.025121   \n",
       "2   0.061101   0.054006   0.094082   0.101140   0.101661     0.034098   \n",
       "3   0.024583   0.080417   0.095417   0.075556   0.068958     0.042639   \n",
       "4   0.051856   0.037239   0.120742   0.054270   0.070285     0.011185   \n",
       "\n",
       "   inc_125_149  inc_150_199  inc_gt_200     city_key state_key  year  \n",
       "0     0.006508     0.018748    0.002014      Abilene        TX  2006  \n",
       "1     0.003552     0.000000    0.000000       Albany        NY  2006  \n",
       "2     0.007486     0.009591    0.005456  Albuquerque        NM  2006  \n",
       "3     0.000000     0.021458    0.000000    Allentown     PA-NJ  2006  \n",
       "4     0.022496     0.000000    0.009405     Amarillo        TX  2006  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############\n",
    "# Income Data\n",
    "###############\n",
    "inc_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    if year == 2006:\n",
    "        f = 'ACS_06_EST_B19001F'\n",
    "    else:\n",
    "        f = 'ACS_' + str(year)[2:] + '_1YR_B19001F'\n",
    "    inc = pd.read_csv(\"data/house_income/%s.csv\" %f, encoding='Latin-1')\n",
    "    # Keep only the estimates\n",
    "    inc = slim_df(inc, [v for v in inc.columns if \"HD01\" in v])\n",
    "    inc['year'] = year\n",
    "    inc_all = append_df(inc, inc_all) \n",
    "\n",
    "# Proccess Final Data Frame\n",
    "inc_all =  inc_all.rename(index=str,\n",
    "                          columns={'HD01_VD01':'total',\n",
    "                                  'HD01_VD02': 'inc_lt10',\n",
    "                                  'HD01_VD03': 'inc_10_15',\n",
    "                                  'HD01_VD04': 'inc_15_19',\n",
    "                                  'HD01_VD05': 'inc_20_24',\n",
    "                                  'HD01_VD06': 'inc_25_29',\n",
    "                                  'HD01_VD07': 'inc_30_34',\n",
    "                                  'HD01_VD08': 'inc_35_39',\n",
    "                                  'HD01_VD09': 'inc_40_44',\n",
    "                                  'HD01_VD10': 'inc_45_49',\n",
    "                                  'HD01_VD11': 'inc_50_59',\n",
    "                                  'HD01_VD12': 'inc_60_74',\n",
    "                                  'HD01_VD13':'inc_75_99',\n",
    "                                  'HD01_VD14':'inc_100_124',\n",
    "                                  'HD01_VD15':'inc_125_149',\n",
    "                                  'HD01_VD16':'inc_150_199',\n",
    "                                  'HD01_VD17':'inc_gt_200'})\n",
    "\n",
    "numeric_vars =  [v for v in inc_all.columns if \"inc\" in v]\n",
    "inc_all[numeric_vars] = inc_all[numeric_vars].astype(int)\n",
    "inc_all['total'] = inc_all['total'].astype(int)\n",
    "# Get propotion of each imcome bracket by dividing by total\n",
    "inc_all.loc[:, numeric_vars] = inc_all[numeric_vars].apply(lambda x: x / inc_all[\"total\"])\n",
    "del inc_all['total']\n",
    "# Match Crime data and Get rid of MSA\n",
    "inc_all = match_crime(inc_all)\n",
    "del inc_all['MSA']\n",
    "inc_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gini</th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.443</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445</td>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.481</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.405</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gini   city_key state_key  year\n",
       "0  0.443    Abilene        TX  2006\n",
       "1  0.533  Aguadilla        PR  2006\n",
       "2  0.445      Akron        OH  2006\n",
       "3  0.481     Albany        GA  2006\n",
       "4  0.405     Albany        NY  2006"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############\n",
    "# GINI INDEX\n",
    "###############\n",
    "gini_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    if year == 2006:\n",
    "        f = 'ACS_06_EST_B19083'\n",
    "    else:\n",
    "        f = 'ACS_' + str(year)[2:] + '_1YR_B19083'\n",
    "    gini = pd.read_csv(\"data/gini/%s.csv\" %f, encoding='Latin-1')\n",
    "    # Don't need micro areas\n",
    "    micro_area = gini['GEO.display-label'].str.contains(\"Micro Area\")\n",
    "    gini = gini.loc[~micro_area, :]\n",
    "    gini = slim_df(gini, [\"HD01_VD01\"])\n",
    "    gini['year'] = year\n",
    "    gini_all = append_df(gini, gini_all) \n",
    "\n",
    "# Clean Final Dataframes\n",
    "gini_all = gini_all.rename(index=str,\n",
    "                           columns={\"HD01_VD01\":\"gini\"})\n",
    "gini_all['gini'] = gini_all['gini'].astype(float)\n",
    "del gini_all['MSA']\n",
    "gini_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Head of Household Information\n",
    "#################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nedu = pd.read_csv(\"data/education/ACS_06_EST_B15001.csv\", encoding=\\'Latin-1\\')\\n\\n# There are too many variables\\n\\n# I am going to create 4 groupings. \\n# male - no hs number, male - high school graduates and same for female\\n# Then I will sum up the variables to create aggregates above\\n\\n\\n# Going to get the variables for 9-12 no diploma for male and female\\nvar_groups = {}\\nfor g in [\\'Male\\', \\'Female\\']:\\n    g_list = []\\n    for r in edu.columns:\\n        var_desc = edu[r].iloc[0]\\n        # Make sure gender mentioned and 9th grade and estimate\\n        if g in var_desc and \\'9th\\' in var_desc and \\'HD01\\' in r:\\n            g_list.append(r)\\n    var_groups[\\'no_hs_%s\\' %g] = g_list\\n\\nprint(var_groups)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################\n",
    "# Education Data\n",
    "#################\n",
    "'''\n",
    "edu = pd.read_csv(\"data/education/ACS_06_EST_B15001.csv\", encoding='Latin-1')\n",
    "\n",
    "# There are too many variables\n",
    "\n",
    "# I am going to create 4 groupings. \n",
    "# male - no hs number, male - high school graduates and same for female\n",
    "# Then I will sum up the variables to create aggregates above\n",
    "\n",
    "\n",
    "# Going to get the variables for 9-12 no diploma for male and female\n",
    "var_groups = {}\n",
    "for g in ['Male', 'Female']:\n",
    "    g_list = []\n",
    "    for r in edu.columns:\n",
    "        var_desc = edu[r].iloc[0]\n",
    "        # Make sure gender mentioned and 9th grade and estimate\n",
    "        if g in var_desc and '9th' in var_desc and 'HD01' in r:\n",
    "            g_list.append(r)\n",
    "    var_groups['no_hs_%s' %g] = g_list\n",
    "\n",
    "print(var_groups)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSA</th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.741838</td>\n",
       "      <td>0.068295</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aguadilla-Isabela-San Sebastián, PR</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.896527</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akron, OH</td>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>0.844866</td>\n",
       "      <td>0.116880</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany, GA</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>0.485957</td>\n",
       "      <td>0.494136</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.867237</td>\n",
       "      <td>0.070216</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    MSA   city_key state_key     white  \\\n",
       "0                          Abilene, TX     Abilene        TX  0.741838   \n",
       "1  Aguadilla-Isabela-San Sebastián, PR   Aguadilla        PR  0.896527   \n",
       "2                            Akron, OH       Akron        OH  0.844866   \n",
       "3                           Albany, GA      Albany        GA  0.485957   \n",
       "4          Albany-Schenectady-Troy, NY      Albany        NY  0.867237   \n",
       "\n",
       "      black     asian  year  \n",
       "0  0.068295  0.014292  2006  \n",
       "1  0.019961  0.000758  2006  \n",
       "2  0.116880  0.017715  2006  \n",
       "3  0.494136  0.006355  2006  \n",
       "4  0.070216  0.030761  2006  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Race Data\n",
    "############\n",
    "race_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    if year == 2006:\n",
    "        f = 'ACS_06_EST_B02001'\n",
    "    else:\n",
    "        f = 'ACS_' + str(year)[2:] + '_1YR_B02001'\n",
    "    race = pd.read_csv(\"data/race/%s.csv\" %f, encoding='Latin-1')\n",
    "    race = slim_df(race, [v for v in race.columns if \"HD01\" in v])\n",
    "    race = race.loc[:, ['MSA', 'city_key', 'state_key',\n",
    "                       'HD01_VD01','HD01_VD02',\n",
    "                       'HD01_VD03', 'HD01_VD05']]\n",
    "    \n",
    "    race['year'] = year\n",
    "    race_all = append_df(race, race_all) \n",
    "\n",
    "# Proccess Final Data Frame\n",
    "race_all =  race_all.rename(index=str,\n",
    "                            columns={'HD01_VD01':'total',\n",
    "                                    'HD01_VD02': 'white',\n",
    "                                    'HD01_VD03': 'black',\n",
    "                                    'HD01_VD05': 'asian'})\n",
    "\n",
    "race_num_v = ['total', 'white','black','asian']\n",
    "race_all[race_num_v] = race_all[race_num_v].astype(int)\n",
    "race_all[race_num_v] = race_all[race_num_v].apply(lambda x: x / race_all[\"total\"])\n",
    "del race_all['total']\n",
    "# Match Crime Data\n",
    "race_all = match_crime(race_all)\n",
    "race_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment Merge Stats\n",
      "both          4118\n",
      "right_only      36\n",
      "left_only        0\n",
      "Name: _merge, dtype: int64\n",
      "Age Merge Stats\n",
      "both          4154\n",
      "right_only       0\n",
      "left_only        0\n",
      "Name: _merge, dtype: int64\n",
      "Income Merge Stats\n",
      "left_only     3121\n",
      "both          1033\n",
      "right_only       0\n",
      "Name: _merge, dtype: int64\n",
      "Gini Merge Stats\n",
      "Blake checked these. no typos\n",
      "both          4079\n",
      "right_only      75\n",
      "left_only       75\n",
      "Name: _merge, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Bring Everything Together\n",
    "census_df = race_all.copy()\n",
    "\n",
    "merge_df = lambda df: census_df.merge(df,\n",
    "                                     how='outer',\n",
    "                                     on=['city_key','state_key','year'],\n",
    "                                     indicator=True)\n",
    "\n",
    "# Merge in Employment\n",
    "census_df = merge_df(emp_all)\n",
    "\n",
    "# Check to see if any non-matches that should be matches\n",
    "# All left matched so we should be good\n",
    "print(\"Employment Merge Stats\")\n",
    "print(census_df['_merge'].value_counts())\n",
    "del census_df['_merge']\n",
    "\n",
    "# Merge in House Income\n",
    "census_df = merge_df(age_all)\n",
    "print(\"Age Merge Stats\")\n",
    "print(census_df['_merge'].value_counts())\n",
    "del census_df['_merge']\n",
    "\n",
    "# Bring in INcome\n",
    "census_df = merge_df(inc_all)\n",
    "print(\"Income Merge Stats\")\n",
    "print(census_df['_merge'].value_counts())\n",
    "del census_df['_merge']\n",
    "\n",
    "# Merge in Gini\n",
    "census_df = merge_df(gini_all)\n",
    "print(\"Gini Merge Stats\")\n",
    "print(\"Blake checked these. no typos\")\n",
    "print(census_df['_merge'].value_counts())\n",
    "del census_df['_merge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSA</th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "      <th>year</th>\n",
       "      <th>unemp_16_ovr</th>\n",
       "      <th>unemp_16_19</th>\n",
       "      <th>unemp_female</th>\n",
       "      <th>...</th>\n",
       "      <th>inc_40_44</th>\n",
       "      <th>inc_45_49</th>\n",
       "      <th>inc_50_59</th>\n",
       "      <th>inc_60_74</th>\n",
       "      <th>inc_75_99</th>\n",
       "      <th>inc_100_124</th>\n",
       "      <th>inc_125_149</th>\n",
       "      <th>inc_150_199</th>\n",
       "      <th>inc_gt_200</th>\n",
       "      <th>gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.741838</td>\n",
       "      <td>0.068295</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>2006</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044159</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.138829</td>\n",
       "      <td>0.060738</td>\n",
       "      <td>0.099628</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aguadilla-Isabela-San Sebastián, PR</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.896527</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>2006</td>\n",
       "      <td>20.6</td>\n",
       "      <td>56.8</td>\n",
       "      <td>19.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akron, OH</td>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>0.844866</td>\n",
       "      <td>0.116880</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>2006</td>\n",
       "      <td>6.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany, GA</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>0.485957</td>\n",
       "      <td>0.494136</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>2006</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.867237</td>\n",
       "      <td>0.070216</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>2006</td>\n",
       "      <td>5.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.071048</td>\n",
       "      <td>0.108094</td>\n",
       "      <td>0.062928</td>\n",
       "      <td>0.046435</td>\n",
       "      <td>0.025121</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    MSA   city_key state_key     white  \\\n",
       "0                          Abilene, TX     Abilene        TX  0.741838   \n",
       "1  Aguadilla-Isabela-San Sebastián, PR   Aguadilla        PR  0.896527   \n",
       "2                            Akron, OH       Akron        OH  0.844866   \n",
       "3                           Albany, GA      Albany        GA  0.485957   \n",
       "4          Albany-Schenectady-Troy, NY      Albany        NY  0.867237   \n",
       "\n",
       "      black     asian  year  unemp_16_ovr  unemp_16_19  unemp_female  ...    \\\n",
       "0  0.068295  0.014292  2006           6.6         23.1           5.2  ...     \n",
       "1  0.019961  0.000758  2006          20.6         56.8          19.1  ...     \n",
       "2  0.116880  0.017715  2006           6.3         23.0           4.8  ...     \n",
       "3  0.494136  0.006355  2006          10.0         31.0          10.1  ...     \n",
       "4  0.070216  0.030761  2006           5.4         16.8           4.4  ...     \n",
       "\n",
       "   inc_40_44  inc_45_49  inc_50_59  inc_60_74  inc_75_99  inc_100_124  \\\n",
       "0   0.044159   0.004803   0.138829   0.060738   0.099628     0.004029   \n",
       "1        NaN        NaN        NaN        NaN        NaN          NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN          NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN          NaN   \n",
       "4   0.011165   0.071048   0.108094   0.062928   0.046435     0.025121   \n",
       "\n",
       "   inc_125_149  inc_150_199  inc_gt_200   gini  \n",
       "0     0.006508     0.018748    0.002014  0.443  \n",
       "1          NaN          NaN         NaN  0.533  \n",
       "2          NaN          NaN         NaN  0.445  \n",
       "3          NaN          NaN         NaN  0.481  \n",
       "4     0.003552     0.000000    0.000000  0.405  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_cols = census_df.columns.difference([\"MSA\", \"city_key\", \"state_key\",\"year\"])\n",
    "census_df[float_cols] = census_df[float_cols].astype(float)\n",
    "census_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Bring in BEA Data\n",
    "#####################\n",
    "bea_gdp = pd.read_csv(\"data/BEA_real_GDP_pc.csv\",skiprows=[0,1,2], header=1)\n",
    "del bea_gdp['Fips']\n",
    "bea_gdp= bea_gdp.iloc[1:, :].rename(index=str, columns={\"Area\": 'MSA'})\n",
    "bea_gdp = pd.melt(bea_gdp, id_vars=[\"MSA\"], var_name='year', value_name='real_pc_gdp')\n",
    "bea_gdp = bea_gdp.loc[bea_gdp.MSA.notnull(), :]\n",
    "bea_gdp['year'] = bea_gdp['year'].astype(int)\n",
    "bea_gdp = bea_gdp.loc[bea_gdp.year >= 2006, :]\n",
    "\n",
    "# Get rid of MSA in paranthesis\n",
    "bea_gdp['MSA'] = bea_gdp['MSA'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "bea_gdp = split_MSA(bea_gdp)\n",
    "del bea_gdp['MSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bea Merge Stats\n",
      "both          4004\n",
      "left_only      225\n",
      "right_only     198\n",
      "Name: _merge, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "census_df = merge_df(bea_gdp)\n",
    "print(\"Bea Merge Stats\")\n",
    "print(census_df['_merge'].value_counts())\n",
    "#del census_df['_merge']\n",
    "census_df = census_df.sort_values([\"MSA\"])\n",
    "# Look at left right combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure that there were no typos\n",
    "names = census_df.loc[census_df._merge != \"both\", ['city_key', 'state_key', '_merge']]\n",
    "names = names.drop_duplicates()\n",
    "print(names.shape[0])\n",
    "del census_df[\"_merge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSA</th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "      <th>year</th>\n",
       "      <th>unemp_16_ovr</th>\n",
       "      <th>unemp_16_19</th>\n",
       "      <th>unemp_female</th>\n",
       "      <th>...</th>\n",
       "      <th>inc_45_49</th>\n",
       "      <th>inc_50_59</th>\n",
       "      <th>inc_60_74</th>\n",
       "      <th>inc_75_99</th>\n",
       "      <th>inc_100_124</th>\n",
       "      <th>inc_125_149</th>\n",
       "      <th>inc_150_199</th>\n",
       "      <th>inc_gt_200</th>\n",
       "      <th>gini</th>\n",
       "      <th>real_pc_gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.741838</td>\n",
       "      <td>0.068295</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>2006</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.138829</td>\n",
       "      <td>0.060738</td>\n",
       "      <td>0.099628</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>33978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.832574</td>\n",
       "      <td>0.079190</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>2012</td>\n",
       "      <td>6.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>35406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.840689</td>\n",
       "      <td>0.085917</td>\n",
       "      <td>0.016213</td>\n",
       "      <td>2011</td>\n",
       "      <td>6.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4344</td>\n",
       "      <td>33964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.782534</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>0.015273</td>\n",
       "      <td>2014</td>\n",
       "      <td>5.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4626</td>\n",
       "      <td>39776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.843283</td>\n",
       "      <td>0.074948</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4590</td>\n",
       "      <td>34004.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MSA city_key state_key     white     black     asian  year  \\\n",
       "0     Abilene, TX   Abilene        TX  0.741838  0.068295  0.014292  2006   \n",
       "2208  Abilene, TX   Abilene        TX  0.832574  0.079190  0.015352  2012   \n",
       "1835  Abilene, TX   Abilene        TX  0.840689  0.085917  0.016213  2011   \n",
       "2963  Abilene, TX   Abilene        TX  0.782534  0.073649  0.015273  2014   \n",
       "1466  Abilene, TX   Abilene        TX  0.843283  0.074948  0.010210  2010   \n",
       "\n",
       "      unemp_16_ovr  unemp_16_19  unemp_female     ...       inc_45_49  \\\n",
       "0              6.6         23.1           5.2     ...        0.004803   \n",
       "2208           6.8         19.7           6.5     ...             NaN   \n",
       "1835           6.9         19.8           6.6     ...             NaN   \n",
       "2963           5.1         13.0           4.9     ...             NaN   \n",
       "1466           8.5         19.9           7.7     ...             NaN   \n",
       "\n",
       "      inc_50_59  inc_60_74  inc_75_99  inc_100_124  inc_125_149  inc_150_199  \\\n",
       "0      0.138829   0.060738   0.099628     0.004029     0.006508     0.018748   \n",
       "2208        NaN        NaN        NaN          NaN          NaN          NaN   \n",
       "1835        NaN        NaN        NaN          NaN          NaN          NaN   \n",
       "2963        NaN        NaN        NaN          NaN          NaN          NaN   \n",
       "1466        NaN        NaN        NaN          NaN          NaN          NaN   \n",
       "\n",
       "      inc_gt_200    gini  real_pc_gdp  \n",
       "0       0.002014  0.4430      33978.0  \n",
       "2208         NaN  0.4851      35406.0  \n",
       "1835         NaN  0.4344      33964.0  \n",
       "2963         NaN  0.4626      39776.0  \n",
       "1466         NaN  0.4590      34004.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df.to_json(\"output/census_df.json\")\n",
    "census_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
