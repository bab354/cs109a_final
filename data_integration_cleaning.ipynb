{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used **three** primary sources for our project. For all sources, we gathered data for the years **2006 - 2016**. Observational unit for study was **Metropolitan Statistical Area (MSA).** An MSA is defined to be a geographical area with high population density.\n",
    "\n",
    "### 1. FBI Uniform Crime Reporting (UCR) Program ###\n",
    "\n",
    "We **automated** the extraction murders and man-slaughter data from the FBI database for the years 2006 - 2017.**Table 1** lists the features provided in the FBI database.\n",
    "\n",
    "<center> ** Table 1: List of Crime Variables from FBI ** </center>\n",
    "\n",
    "|          Name          |\n",
    "|:--------------------------------|\n",
    "| Violent Crime                     |\n",
    "| Murder + Non-negligent Manslaughter|\n",
    "| Forcible Rape               |\n",
    "| Robbery                  |\n",
    "| Aggravated Assault            |\n",
    "| Property Crime           |\n",
    "| Burglary           |\n",
    "| Larceny-theft                |\n",
    "| Motor Vehicle Theft                |\n",
    "| Population of MSA         |\n",
    "| Population of Largest city within MSA          |\n",
    "\n",
    "The crime variables listed in Table 1 were available in three separate forms: Number for entire MSA, Number within the largest city of the MSA, and the number across the MSA per 100,000 individuals (a rate).\n",
    "\n",
    "*URL: https://ucr.fbi.gov/ucr-publications*\n",
    "\n",
    "### 2. United States Census Bureau (UCSB) ###\n",
    "\n",
    "We obtained demographic data for each MSA from the USCB.  We used our EDA (Exploratory Data Analysis), intuition, and the provided Glaeser paper to identify the features in scope. **Table 2** list the names, definitions, and table numbers for which we got census data.\n",
    "\n",
    "<center> ** Table 2: Census Features Pulled for our analysis ** </center>\n",
    "\n",
    "\n",
    "|          Feature Name          | Feature Definition | USCB Table Number |\n",
    "|--------------------------------|---|----------------------------------------------------------------------|\n",
    "| white | % of White people | B02001 \n",
    "| black | % of Black people | B02001\n",
    "| asian | % of Asian people | B02001\n",
    "| unemp_16_ovr | % Unemployed (age 16 years and over) | S2301\n",
    "| unemp_16_19 | % Unemployed (age 16-19) | S2301\n",
    "| unemp_female | % Unemployed Female | S2301\n",
    "| median age| Median Age | S0101\n",
    "| sex_ratio | Number of Males per 100 females | S0101\n",
    "| male_pop | % Male Population | S0101\n",
    "| female_pop | % Female Population | S0101\n",
    "| pop_15_19 | % of Population age 15-19 | S0101\n",
    "| pop_20_24 | % of Population age 20-24 | S0101\n",
    "| male_pop_20_24 | % Male Population age 20-24 | S0101\n",
    "| married_house | % of Households with married couples | B09005\n",
    "| female_house | % of Single Households led by female | B09005\n",
    "| male_house | % of Single Households led by male | B09005\n",
    "| no_hs_18_24 | % of 18-24 year olds with no high school | S1501\n",
    "| hs_18_24 | % of 18-24 year olds with high school | S1501\n",
    "| no_9th_25_ovr | % of age 25 and over with less than 9th grade | S1501\n",
    "| no_hs_25_ovr | % of age 25 and over with no high school | S1501\n",
    "| hs_25_ovr | % of age 25 and over with high school | S1501\n",
    "| gini | Gini Index | B19083\n",
    "| under_18_pov  | poverty_rate among 18 and under | S1701\n",
    "| 18_64_pov | poverty_rate among 18-64 years | S1701\n",
    "| male_pov | povery_rate among males | S1701\n",
    "| female_pov | poverty_rate among females  | S1701\n",
    "\n",
    "We selected these variables because data were widely available (by year and by MSA) and we wanted to try to collect a range of economic, gender, racial, and age features to get a diverse array of variables about an MSA.\n",
    "\n",
    "*URL: https://factfinder.census.gov/*\n",
    "\n",
    "### 3. Bureau of Economic Analysis (BEA) ###\n",
    "\n",
    "The data on income from UCSB were mostly missing and thus unusable.  Instead, we looked to the BEA which provided **real per-capita GDP**, that measures an MSA aggregate economic activity.  The reason we chose real per-capita GDP are two-fold. Per-capita GDP is better than GDP for our purposes because it adjusts for population. Otherwise, larger MSA will always have larger GDP due to more people and resources. Secondly, real per capita GDP was chosen to control for inflation. Our GDP measure is in 2005 dollars for all years so that comparisons between years is due to actual changes rather than inflation\n",
    "\n",
    "*URL: https://www.bea.gov/iTable/iTable.cfm?ReqID=70#reqid=70&step=1&isuri=1&7003=1000&7004=naics&7035=-1&7005=1&7006=xx&7001=21000&7036=-1&7002=2&7090=70&7007=-1&7093=levels*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration & Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listed below are the gaps that we've identified in the extracted data, alongside the design decisions we made for re-formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crime Data (FBI Uniform Crime Reporting Program):**\n",
    "\n",
    "* Some MSA had crime statistics within multiple cities while the others only had one. We decided to define our city features as those that come from the largest city (by population) so that each MSA had one set of city statistics\n",
    "\n",
    "\n",
    "* Not all MSA had 100% reporting rate of data. For those MSAs that did not have 100% reporting, an estimated total was reported. We used the estimated total rather than the actual variables so that all of our data represented the entire MSA (either actual or estimated).\n",
    "\n",
    "\n",
    "* Crime data did not have a numeric ID for MSA. We initially considered using a cross-walk to translate the MSA descriptions to IDs but decided otherwise since IDs changed over time. MSA desciptions were a concatenation of the key cities followed by the state name. There were instances where an MSA was part of multiple states. We also observed that MSA names change over time. For accurate and unique identification, we created a unique **join_key** for each MSA. To create the join key, we extracted the first city name from the MSA description and concantenated it with the state abbreviation (which was also a part of the MSA description). We then used this **join_key along with year to merge the three data sets** to create one complete data frame for subsequent analysis.\n",
    "\n",
    "**Census Data:**\n",
    "\n",
    "We created custom tables at the M.S.A level from the census database and extracted the files in Excel format. These files were merged into a census dataframe, which was later joined back to the Crime Dataset\n",
    "\n",
    "* Around 4% of MSA descriptions differed from what we obtained from the FBI Database. These cases were manually updated.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "---------------\n",
    "split_MSA\n",
    "\n",
    "This method takes in a dataframe with MSA and splits into a city_key (largest city)\n",
    "and state_key. This will help facilitate MSA merging\n",
    "\n",
    "Returns dataframe with these two additional features\n",
    "\"\"\"\n",
    "def split_MSA(df):\n",
    "    df['MSA'] = df['MSA'].str.replace('Metro Area', '')\n",
    "    # Need to manually fix how this MSA is written\n",
    "    df.loc[df['MSA'].str.contains(\"Texarkana\"), \"MSA\"] = \"Texarkana, AR-TX\"\n",
    "\n",
    "    #Grab Everything before comma\n",
    "    df['city_key'] = df['MSA'].str.split(\",\").str[0]\n",
    "    # Then grab everything before first hyphen if it has it\n",
    "    df['city_key'] = df['city_key'].str.split(\"-\").str[0].str.strip()\n",
    "    # State will be everying after comma \n",
    "    df['state_key']=df['MSA'].str.split(\",\").str[1].str.strip()\n",
    "    return(df)\n",
    "\n",
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "append_df\n",
    "\n",
    "This function appends two dataframes\n",
    "\n",
    "Parameters:\n",
    "    input - dataframe to be appended\n",
    "    output - dataframe to be appended onto\n",
    "    \n",
    "Returns a single dataframe \n",
    "\"\"\"\n",
    "def append_df(input,output):\n",
    "    if output.empty:\n",
    "        output=input.copy()\n",
    "    else:\n",
    "        output=pd.concat([output,input])\n",
    "        output.reset_index(drop='Index',inplace=True)\n",
    "    return(output)\n",
    "\n",
    "'''\n",
    "Function\n",
    "-----------\n",
    "var_thresh\n",
    "\n",
    "This function takes in a dataframe and keeps only those varaibles that have a pct\n",
    "non-missing that is above that threshold\n",
    "'''\n",
    "def var_thresh(df, thresh=0.65):\n",
    "    return(df.loc[:, pd.notnull(df).sum() > len (df) *thresh])\n",
    "\n",
    "'''\n",
    "Function\n",
    "---------\n",
    "slim_df\n",
    "\n",
    "This function takes in a list of variables to keep\n",
    "on the the given df. It keep the variables + geography\n",
    "then renames to MSA and drops the first row of variable descriptions\n",
    "'''\n",
    "def slim_df(df, var_list):\n",
    "    var_list.append('GEO.display-label')\n",
    "    df = df.loc[:, var_list]\n",
    "    # Get rid of Micro Areas\n",
    "    df = df.loc[~df['GEO.display-label'].str.contains(\"Micro Area\"), :]\n",
    "    \n",
    "    df = df.rename(index=str, columns={'GEO.display-label': 'MSA'})\n",
    "    df['MSA'] = df[\"MSA\"].astype(str)\n",
    "    # Drop first row of var descriptions\n",
    "    df = df.loc[df.MSA != \"Geography\", :]\n",
    "    # Split MSA into city-state key\n",
    "    return(split_MSA(df))\n",
    "\n",
    "'''\n",
    "Function\n",
    "---------\n",
    "match_crime\n",
    "\n",
    "This function will take in a dataframe and make changes to MSA\n",
    "in order to match crime data\n",
    "'''\n",
    "def match_crime(df):\n",
    "    df.loc[df['MSA'].str.contains('Crestview'),'city_key']='Crestview'\n",
    "    df.loc[df['MSA'].str.contains('Sarasota'),'city_key']='North Port'\n",
    "    df.loc[df['MSA'].str.contains('Louisville'),'city_key']='Louisville'\n",
    "    df.loc[df['MSA'].str.contains('Santa Maria'),'city_key']='Santa Maria'\n",
    "    df.loc[df['MSA'].str.contains('Weirton'),'city_key']='Weirton'\n",
    "    df.loc[df['MSA'].str.contains('San Germán'),'city_key']='San German'\n",
    "    df.loc[df['MSA'].str.contains('Mayagüez'),'city_key']='Mayaguez'\n",
    "    df.loc[df['MSA'].str.contains('Honolulu'),'city_key']='Urban Honolulu'\n",
    "\n",
    "    #State\n",
    "    df.loc[df['MSA'].str.contains('Worcester'),'state_key']='MA-CT'\n",
    "    df.loc[df['MSA'].str.contains('Myrtle Beach'),'state_key']='SC-NC'\n",
    "    df.loc[df['MSA'].str.contains('Salisbury'),'state_key']='MD-DE'\n",
    "    df.loc[df['MSA'].str.contains('Weirton'),'state_key']='WV-OH'\n",
    "    return(df)\n",
    "\n",
    "'''\n",
    "Function\n",
    "--------\n",
    "get_file_name\n",
    "\n",
    "Get the appropriate file name giving year and table code\n",
    "\n",
    "'''\n",
    "def get_file_name(year, table_code):\n",
    "    if year == 2006:\n",
    "        mid = 'EST'\n",
    "    else:\n",
    "        mid = '1YR'\n",
    "    return('ACS_'+str(year)[2:]+\"_%s_\" %mid + table_code)\n",
    "\n",
    "'''\n",
    "Function\n",
    "--------\n",
    "convert_to_int\n",
    "\n",
    "This function takes in a dataframe and list of vars to convert to int\n",
    "'''\n",
    "def convert_to_int(df, int_vars):\n",
    "    df[int_vars] = df[int_vars].astype(int)\n",
    "    return(df)\n",
    "'''\n",
    "Function\n",
    "----------\n",
    "create_proportions\n",
    "\n",
    "This function will take in a list of variables and a single total variable\n",
    "It then creates proportions by dividing each of the variables in the list by the total\n",
    "to create a proportion\n",
    "'''\n",
    "def create_proportions(df,num_list, total_var):\n",
    "    df.loc[:, num_list] = df[num_list].apply(lambda x: x / df[total_var])\n",
    "    del df[total_var]\n",
    "    return(df)\n",
    "\n",
    "\"\"\"\n",
    "function\n",
    "-----------\n",
    "fbi_url_generator\n",
    "\n",
    "This function pulls violent crime spreadsheets from FBI UCR website\n",
    "for a given year\n",
    "\n",
    "It takes in the year of interest and outputs a url string\n",
    "\"\"\"\n",
    "def fbi_url_generator(year):\n",
    "    if 2006 <= year <= 2009:\n",
    "        return('https://www2.fbi.gov/ucr/cius%i/data/documents/'%year +str(year)[2:]+'tbl06.xls')\n",
    "    else:\n",
    "        if 2010 <= year <= 2011:\n",
    "            end = '/tables/table-6/output.xls'\n",
    "        elif 2012 <= year <= 2013:\n",
    "            end = '/tables/6tabledatadecpdf/table-6/output.xls'\n",
    "        elif 2014 <= year <= 2015:\n",
    "            if year == 2014:\n",
    "                mid = 'Table_6_Crime_in_the_United_States_by_Metropolitan_Statistical_Area_2014/output.xls'\n",
    "            else:\n",
    "                mid = 'table_6_crime_in_the_united_states_by_metropolitan_statistical_area_%i.xls/output.xls' %year\n",
    "            end = '/tables/table-6/%s' %mid\n",
    "        elif year == 2016:\n",
    "            end ='/tables/table-4/table-4/output.xls' \n",
    "        hostname = 'https://ucr.fbi.gov/crime-in-the-u.s/%i/crime-in-the-u.s.-%i' %(year, year)\n",
    "        return(hostname + end)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hide": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "# Employment Data\n",
    "#####################\n",
    "emp_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(2006, 'S2301')\n",
    "    employ = pd.read_csv(\"data/employ/%s.csv\" %f, encoding='Latin-1')\n",
    "    \n",
    "    # Grab Unemployment\n",
    "    un = [v for v in employ.columns if \"HC04\" in v and \"EST\" in v]\n",
    "    employ = slim_df(employ, un)\n",
    "    \n",
    "    employ = employ.loc[:, [\"MSA\", \"city_key\", \"state_key\", \n",
    "                          \"HC04_EST_VC01\", \"HC04_EST_VC03\",\n",
    "                         'HC04_EST_VC24']]\n",
    "    employ['year'] = year\n",
    "    emp_all = append_df(employ, emp_all) \n",
    "\n",
    "# Process Final DataFrame\n",
    "emp_all = emp_all.sort_values(['city_key', 'state_key', 'year'])\n",
    "emp_all = match_crime(emp_all)\n",
    "del emp_all['MSA']\n",
    "emp_all = emp_all.rename(index=str,\n",
    "                        columns={'HC04_EST_VC01': 'unemp_16_ovr',\n",
    "                                'HC04_EST_VC03': 'unemp_16_19',\n",
    "                                'HC04_EST_VC24': 'unemp_female'})\n",
    "#emp_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "# Age Data\n",
    "############\n",
    "age_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'S0101')\n",
    "    age = pd.read_csv(\"data/age/%s.csv\" %f, encoding='Latin-1')\n",
    "    age = slim_df(age, [v for v in age.columns if \"EST\" in v])\n",
    "    age = age.replace(\"(X)\", np.nan)\n",
    "\n",
    "    age = age.loc[:, ['MSA','city_key','state_key',\n",
    "                      'HC01_EST_VC33','HC01_EST_VC34',\n",
    "                      'HC01_EST_VC01', 'HC02_EST_VC01',\n",
    "                      'HC03_EST_VC01', 'HC01_EST_VC06',\n",
    "                      'HC01_EST_VC07', 'HC02_EST_VC07']]\n",
    "    age['year'] = year\n",
    "    age_all = append_df(age, age_all) \n",
    "\n",
    "\n",
    "# Process Final DataFrame\n",
    "age_all = age_all.sort_values(['city_key', 'state_key', 'year'])\n",
    "age_all = age_all.rename(index=str,\n",
    "                         columns={'HC01_EST_VC33':'median_age',\n",
    "                                'HC01_EST_VC34': 'sex_ratio',\n",
    "                                'HC01_EST_VC01': 'total_pop',\n",
    "                                'HC02_EST_VC01': 'male_pop',\n",
    "                                'HC03_EST_VC01': 'female_pop',\n",
    "                                'HC01_EST_VC06': 'pop_15_19',\n",
    "                                'HC01_EST_VC07': 'pop_20_24',\n",
    "                                'HC02_EST_VC07': 'male_pop_20_24'})\n",
    "\n",
    "# Convert to Int and Get Proportions\n",
    "age_all = convert_to_int(age_all, ['total_pop', 'male_pop', 'female_pop'])\n",
    "age_all = create_proportions(age_all, ['male_pop', 'female_pop'], 'total_pop')\n",
    "# Match Crime Data and then get rid of MSA\n",
    "age_all = match_crime(age_all)\n",
    "del age_all['MSA']\n",
    "#age_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# Income Data\n",
    "###############\n",
    "inc_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'B19001F')\n",
    "    inc = pd.read_csv(\"data/house_income/%s.csv\" %f, encoding='Latin-1')\n",
    "    # Keep only the estimates\n",
    "    inc = slim_df(inc, [v for v in inc.columns if \"HD01\" in v])\n",
    "    inc['year'] = year\n",
    "    inc_all = append_df(inc, inc_all) \n",
    "\n",
    "# Proccess Final Data Frame\n",
    "inc_all =  inc_all.rename(index=str,\n",
    "                          columns={'HD01_VD01':'total',\n",
    "                                  'HD01_VD02': 'inc_lt10',\n",
    "                                  'HD01_VD03': 'inc_10_15',\n",
    "                                  'HD01_VD04': 'inc_15_19',\n",
    "                                  'HD01_VD05': 'inc_20_24',\n",
    "                                  'HD01_VD06': 'inc_25_29',\n",
    "                                  'HD01_VD07': 'inc_30_34',\n",
    "                                  'HD01_VD08': 'inc_35_39',\n",
    "                                  'HD01_VD09': 'inc_40_44',\n",
    "                                  'HD01_VD10': 'inc_45_49',\n",
    "                                  'HD01_VD11': 'inc_50_59',\n",
    "                                  'HD01_VD12': 'inc_60_74',\n",
    "                                  'HD01_VD13':'inc_75_99',\n",
    "                                  'HD01_VD14':'inc_100_124',\n",
    "                                  'HD01_VD15':'inc_125_149',\n",
    "                                  'HD01_VD16':'inc_150_199',\n",
    "                                  'HD01_VD17':'inc_gt_200'})\n",
    "\n",
    "numeric_vars =  [v for v in inc_all.columns if \"inc\" in v]\n",
    "inc_all = convert_to_int(inc_all, numeric_vars)\n",
    "inc_all['total'] = inc_all['total'].astype(int)\n",
    "# Get propotion of each imcome bracket by dividing by total\n",
    "inc_all = create_proportions(inc_all, numeric_vars, \"total\")\n",
    "# Match Crime data and Get rid of MSA\n",
    "inc_all = match_crime(inc_all)\n",
    "del inc_all['MSA']\n",
    "#inc_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# GINI INDEX\n",
    "###############\n",
    "gini_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'B19083')\n",
    "    gini = pd.read_csv(\"data/gini/%s.csv\" %f, encoding='Latin-1')\n",
    "    # Don't need micro areas\n",
    "    gini = slim_df(gini, [\"HD01_VD01\"])\n",
    "    gini['year'] = year\n",
    "    gini_all = append_df(gini, gini_all) \n",
    "\n",
    "# Clean Final Dataframes\n",
    "gini_all = gini_all.rename(index=str,\n",
    "                           columns={\"HD01_VD01\":\"gini\"})\n",
    "gini_all['gini'] = gini_all['gini'].astype(float)\n",
    "gini_all = match_crime(gini_all)\n",
    "del gini_all['MSA']\n",
    "#gini_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# Poverty Data\n",
    "#################\n",
    "pov_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'S1701')\n",
    "    pov = pd.read_csv(\"data/poverty/%s.csv\" %f, encoding='Latin-1')\n",
    "    pov = slim_df(pov, ['HC03_EST_VC03', 'HC03_EST_VC05',\n",
    "                       'HC03_EST_VC08', 'HC03_EST_VC09'])\n",
    "    pov['year'] = year\n",
    "    pov_all = append_df(pov, pov_all)\n",
    "# Clean Final DataFrame\n",
    "pov_all = pov_all.rename(index=str,\n",
    "                        columns={'HC03_EST_VC03': 'under_18_pov',\n",
    "                                'HC03_EST_VC05':'18_64_pov',\n",
    "                                'HC03_EST_VC08':'male_pov',\n",
    "                                'HC03_EST_VC09':'female_pov'})\n",
    "pov_all = match_crime(pov_all)\n",
    "del pov_all['MSA']\n",
    "#pov_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hide": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Head of Household Information\n",
    "#################################\n",
    "house_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'B09005')\n",
    "    house = pd.read_csv(\"data/house_head/%s.csv\" %f, encoding='Latin-1')\n",
    "    house = slim_df(house, [v for v in house.columns if \"HD01\" in v])\n",
    "    house = house.loc[:, [\"MSA\", \"city_key\", \"state_key\",\n",
    "                         \"HD01_VD01\", \"HD01_VD03\", \"HD01_VD05\",\n",
    "                         \"HD01_VD06\"]]\n",
    "    house['year'] = year\n",
    "    house_all = append_df(house, house_all) \n",
    "\n",
    "# Clean Entire DataFrame\n",
    "house_all = house_all.rename(index=str,\n",
    "                             columns={'HD01_VD01': 'total',\n",
    "                                     'HD01_VD03': 'married_house',\n",
    "                                     'HD01_VD05': 'female_house',\n",
    "                                     'HD01_VD06': 'male_house'})\n",
    "\n",
    "house_all = convert_to_int(house_all,\n",
    "                       ['total', 'married_house', 'female_house', 'male_house'])\n",
    "house_all = create_proportions(house_all, ['married_house', 'female_house', 'male_house'], 'total')\n",
    "house_all = match_crime(house_all)\n",
    "del house_all['MSA']\n",
    "#house_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hide": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# Education Data\n",
    "#################\n",
    "edu_all = pd.DataFrame()\n",
    "for year in range(2006,2017):\n",
    "    f = get_file_name(year, 'S1501')\n",
    "    edu = pd.read_csv(\"data/education/%s.csv\" %f, encoding='Latin-1')\n",
    "    if 2015 <= year <= 2016:\n",
    "        edu = slim_df(edu, ['HC02_EST_VC03', 'HC02_EST_VC04', 'HC02_EST_VC09','HC02_EST_VC10', 'HC02_EST_VC11'])\n",
    "    elif 2010 <= year <= 2014:\n",
    "        edu = slim_df(edu,['HC01_EST_VC02', 'HC01_EST_VC03', 'HC01_EST_VC08','HC01_EST_VC09', 'HC01_EST_VC10'])\n",
    "    else:\n",
    "        edu = slim_df(edu, ['HC01_EST_VC02', 'HC01_EST_VC03', 'HC01_EST_VC07','HC01_EST_VC08', 'HC01_EST_VC09'])\n",
    "    \n",
    "    edu['year'] = year\n",
    "    edu.columns=['no_hs_18_24','hs_18_24','no_9th_25_ovr','no_hs_25_ovr','hs_25_ovr','MSA','city_key','state_key','year']\n",
    "    edu_all = append_df(edu, edu_all)\n",
    "\n",
    "#Trim Final Dataframe\n",
    "edu_all = match_crime(edu_all)\n",
    "del edu_all['MSA']\n",
    "#edu_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "# Race Data\n",
    "############\n",
    "race_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'B02001')\n",
    "    race = pd.read_csv(\"data/race/%s.csv\" %f, encoding='Latin-1')\n",
    "    race = slim_df(race, [v for v in race.columns if \"HD01\" in v])\n",
    "    race = race.loc[:, ['MSA', 'city_key', 'state_key',\n",
    "                       'HD01_VD01','HD01_VD02',\n",
    "                       'HD01_VD03', 'HD01_VD05']]\n",
    "    \n",
    "    race['year'] = year\n",
    "    race_all = append_df(race, race_all)\n",
    "\n",
    "# Proccess Final Data Frame\n",
    "race_all =  race_all.rename(index=str,\n",
    "                            columns={'HD01_VD01':'total',\n",
    "                                    'HD01_VD02': 'white',\n",
    "                                    'HD01_VD03': 'black',\n",
    "                                    'HD01_VD05': 'asian'})\n",
    "\n",
    "race_all = convert_to_int(race_all, ['total', 'white','black','asian'] )\n",
    "race_all = create_proportions(race_all, ['white', 'black', 'asian'], 'total')\n",
    "# Match Crime Data\n",
    "race_all = match_crime(race_all)\n",
    "del race_all['MSA']\n",
    "#race_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHousehold had ones where it looks like there may be mismatches but code below checked it\\n\\nCode to check merges\\nnames = census_df.loc[census_df._merge != \"both\", [\\'city_key\\', \\'state_key\\', \\'_merge\\']]\\nnames = names.sort_values[\\'city_key\\', \\'state_key\\']\\nnames = names.drop_duplicates()\\nprint(names.shape[0])\\nnames.head(50)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring Everything Together\n",
    "census_df = race_all.copy()\n",
    "\n",
    "merge_df = lambda df: census_df.merge(df,\n",
    "                                     how='outer',\n",
    "                                     on=['city_key','state_key','year'],\n",
    "                                     indicator=True)\n",
    "\n",
    "str_list = ['Employment', 'Age', 'Head of House','Education', 'Gini', 'Poverty']\n",
    "df_list = [emp_all, age_all, house_all, edu_all, gini_all, pov_all]\n",
    "\n",
    "for i, df in enumerate(df_list):\n",
    "    census_df = merge_df(df)\n",
    "    #print(\"%s Merge Stats\" %str_list[i])\n",
    "    #print(census_df['_merge'].value_counts())\n",
    "    del census_df['_merge']\n",
    "    \n",
    "'''\n",
    "\n",
    "Household had ones where it looks like there may be mismatches but code below checked it\n",
    "\n",
    "Code to check merges\n",
    "names = census_df.loc[census_df._merge != \"both\", ['city_key', 'state_key', '_merge']]\n",
    "names = names.sort_values['city_key', 'state_key']\n",
    "names = names.drop_duplicates()\n",
    "print(names.shape[0])\n",
    "names.head(50)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "# Bring in BEA Data\n",
    "#####################\n",
    "bea_gdp = pd.read_csv(\"data/BEA_real_GDP_pc.csv\",skiprows=[0,1,2], header=1)\n",
    "del bea_gdp['Fips']\n",
    "bea_gdp= bea_gdp.iloc[1:, :].rename(index=str, columns={\"Area\": 'MSA'})\n",
    "bea_gdp = pd.melt(bea_gdp, id_vars=[\"MSA\"], var_name='year', value_name='real_pc_gdp')\n",
    "bea_gdp = bea_gdp.loc[bea_gdp.MSA.notnull(), :]\n",
    "bea_gdp['year'] = bea_gdp['year'].astype(int)\n",
    "bea_gdp = bea_gdp.loc[bea_gdp.year >= 2006, :]\n",
    "\n",
    "# Get rid of MSA in paranthesis\n",
    "bea_gdp['MSA'] = bea_gdp['MSA'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "bea_gdp = split_MSA(bea_gdp)\n",
    "# Need to manually fix this one so it will merge\n",
    "bea_gdp.loc[bea_gdp.city_key.str.contains(\"Louisville\"), 'city_key'] = 'Louisville'\n",
    "\n",
    "del bea_gdp['MSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "census_df = merge_df(bea_gdp)\n",
    "del census_df[\"_merge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "# Check to make sure that there were no typos\n",
    "#names = census_df.loc[census_df._merge != \"both\", ['city_key', 'state_key', '_merge']]\n",
    "#names = names.drop_duplicates()\n",
    "#print(names.shape[0])\n",
    "#del census_df[\"_merge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hide": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_key\n",
      "state_key\n",
      "white\n",
      "black\n",
      "asian\n",
      "year\n",
      "unemp_16_ovr\n",
      "unemp_16_19\n",
      "unemp_female\n",
      "median_age\n",
      "sex_ratio\n",
      "male_pop\n",
      "female_pop\n",
      "pop_15_19\n",
      "pop_20_24\n",
      "male_pop_20_24\n",
      "married_house\n",
      "female_house\n",
      "male_house\n",
      "no_hs_18_24\n",
      "hs_18_24\n",
      "no_9th_25_ovr\n",
      "no_hs_25_ovr\n",
      "hs_25_ovr\n",
      "gini\n",
      "under_18_pov\n",
      "18_64_pov\n",
      "male_pov\n",
      "female_pov\n",
      "real_pc_gdp\n"
     ]
    }
   ],
   "source": [
    "#census_df.head()\n",
    "for d in census_df.columns:\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "# THIS CODE ONLY NEEDS TO BE RUN ONCE TO BRING IN ALL OF THE EXCEL FILES\n",
    "version='Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36'\n",
    "test=urllib.request.URLopener()\n",
    "test.addheader('User-Agent',version)\n",
    "for year in range(2006, 2017):\n",
    "    #print(\"Pulling: %i\" %year)\n",
    "    test.retrieve(url=fbi_url_generator(year),filename='crime_%i.xls' %year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "df_allyears = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    df = pd.read_excel(\"crime_%i.xls\" %year,skiprows=[0,1],header=1)\n",
    "\n",
    "    #######\n",
    "    # NOTE - misc column has msa population, city population and estimate percentage\n",
    "    ######\n",
    "    df=df.iloc[:,0:12] \n",
    "    df.columns=['MSA', 'counties','misc', 'violent_crime','mur_mans', 'rape', 'robbery',\n",
    "                'assault', 'property', 'burglary', 'larceny','mv_theft']\n",
    "    \n",
    "    df['counties'].replace(' ',np.nan, inplace=True)\n",
    "\n",
    "    # Drop footnotes\n",
    "    footnotes = df['MSA'].str[0].str.isdigit().fillna(False)\n",
    "    df = df.loc[~footnotes, :]\n",
    "    \n",
    "    #Drop blank rows\n",
    "    df = df.dropna(how='all')\n",
    "\n",
    "    # Get rid of numbers in MSA\n",
    "    df['MSA'] = df['MSA'].str.replace('\\d+', '')\n",
    "    # Set empty columns to NaN for MSA\n",
    "    df['MSA'] = df['MSA'].replace(' ', np.nan, regex=False)\n",
    "    \n",
    "    # Sometimes city  names get put in MSA column\n",
    "    # Messes up carry forward\n",
    "    df.loc[df['MSA'].str.contains(\"City of\").fillna(False), \"MSA\"] = np.nan\n",
    "\n",
    "    # Carry MSA name forward to fill in for all cells\n",
    "    df.loc[:,'MSA'] = df.loc[:, 'MSA'].fillna(method='ffill')\n",
    "\n",
    "    ##############\n",
    "    # POPULATION - grab population and fill in for all MSA\n",
    "    ##############\n",
    "    pop_row = df.counties.isnull()\n",
    "    pop = df.loc[pop_row, [\"MSA\", 'misc']]\n",
    "    pop = pop.rename(index=str, columns={'misc': 'msa_pop'})\n",
    "    \n",
    "    # Merge population back in\n",
    "    df = df.loc[~pop_row, :]\n",
    "    df = df.merge(pop, how='outer', on='MSA')\n",
    "\n",
    "    ################\n",
    "    # Descriptions - don't need county descriptions \n",
    "    ################\n",
    "    df = df.loc[df.counties.str.contains(\"Includes\") == False, :]\n",
    "\n",
    "\n",
    "    ###########################################\n",
    "    # GOING LONG TO WIDE FOR CRIME VARIABLES\n",
    "    ###########################################\n",
    "    crime_vars = ['violent_crime','mur_mans', 'rape', 'robbery',\n",
    "                  'assault', 'property', 'burglary', 'larceny','mv_theft']\n",
    "\n",
    "    #########\n",
    "    # CITIES\n",
    "    #########\n",
    "    city_vars = ['MSA', 'counties', 'misc'] + crime_vars\n",
    "    # Split data Frame\n",
    "    cities = df.counties.str.contains(\"City\")\n",
    "    city_df = df.loc[cities, city_vars]\n",
    "    city_df = city_df.rename(index=str, columns={'misc': 'city_pop'})\n",
    "    \n",
    "    # Grab largest city for each MSA and merge back on\n",
    "    city_df = city_df.sort_values(['MSA','city_pop'], ascending=False)\n",
    "    large_city = city_df.groupby('MSA').first().reset_index()\n",
    "\n",
    "    # Rename crime variables to denote city only crime \n",
    "    large_city.columns = ['MSA', 'counties', 'city_pop'] + ['city_' + i for i in crime_vars]\n",
    "    large_city = large_city.rename(index=str, columns={'counties':'largest_city'})\n",
    "    # Get rid of \"City of\"\n",
    "    large_city.loc[:,'largest_city'] = large_city.loc[:, 'largest_city'].str.replace('City of','')\n",
    "    \n",
    "    # Merge back to main dataframe\n",
    "    df = df.loc[~cities, ]\n",
    "    df = df.merge(large_city, how='outer', on='MSA')\n",
    "\n",
    "    ###############\n",
    "    # CRIME RATE\n",
    "    ###############\n",
    "    rates = df.counties.str.contains(\"Rate per\")\n",
    "    rate_vars = ['MSA'] + crime_vars\n",
    "    rates_df = df.loc[rates, rate_vars]\n",
    "    rates_df.columns = ['MSA'] + ['rate_' + i for i in crime_vars]\n",
    "\n",
    "    df = df.loc[~rates, :]\n",
    "    df = df.merge(rates_df, how='outer', on='MSA')\n",
    "\n",
    "    ########################\n",
    "    # MSA-WIDE CRIME STATS\n",
    "    ########################\n",
    "\n",
    "    # If the entire MSA reported then there is just one row of numbers\n",
    "    # If the entire MSA did not report, then there are two rows\n",
    "            # first row is areas that reported\n",
    "            # second report is an estimated total\n",
    "    # We are going to grab the estimates total so our data\n",
    "    # reflects all areas for all MSA\n",
    "\n",
    "    # Create Flag for those that do not have complete coverage\n",
    "    # and are thus estimates\n",
    "    mins = df.groupby('MSA').misc.min().reset_index()\n",
    "    mins.columns = ['MSA', 'min_coverage']\n",
    "    df = df.merge(mins, how='outer', on='MSA')\n",
    "    df['estimate'] = 0\n",
    "    df.loc[df.min_coverage < 1, 'estimate'] = 1\n",
    "    del df['min_coverage']\n",
    "\n",
    "    # Now only keeping rows with coverage = 1\n",
    "    # will either be all area or the estimate for all area\n",
    "    df = df.loc[df.misc == 1, :]\n",
    "\n",
    "    # Now no longer need coverage or whether its estimate or not\n",
    "    del df['misc']\n",
    "    del df['counties']\n",
    "    \n",
    "    df['year'] = year\n",
    "    \n",
    "    # Append to existing Frame\n",
    "    df_allyears = append_df(df, df_allyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "df_allyears = df_allyears.sort_values([\"MSA\", 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Generate the city\n",
    "df_allyears['city_key'] = df_allyears['MSA'].str.replace(' M.S.A.','').str.split(\",\").str[0]\n",
    "df_allyears['city_key'] = df_allyears['city_key'].str.split(\"-\").str[0].str.strip()\n",
    "df_allyears['state_key']=df_allyears['MSA'].str.replace(' M.S.A.','').str.split(\",\").str[1].str.strip().str.replace(' M.S.A','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hide": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Cleanse Crime Data\n",
    "df_allyears=df_allyears[~df_allyears['MSA'].str.contains(' M.D.')]\n",
    "df_allyears.loc[df_allyears['state_key']=='Puerto Rico','state_key']='PR'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Texarkana'),'state_key']='AR-TX'\n",
    "df_allyears.loc[df_allyears['city_key']=='Worcester','state_key']='MA-CT'\n",
    "df_allyears.loc[df_allyears['city_key']=='Steubenville','city_key']='Weirton'\n",
    "df_allyears.loc[df_allyears['city_key']=='Steubenville','state_key']='WV-OH'\n",
    "df_allyears.loc[df_allyears['city_key']=='Honolulu','city_key']='Urban Honolulu'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Scranton'),'city_key']='Scranton'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Sarasota'),'city_key']='North Port'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Santa Maria'),'city_key']='Santa Maria'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Salisbury'),'state_key']='MD-DE'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Sacramento'),'city_key']='Sacramento'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Myrtle Beach'),'state_key']='SC-NC'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Louisville'),'city_key']='Louisville'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Homosassa'),'city_key']='Homosassa Springs'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Crestview'),'city_key']='Crestview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "#Merge Crime and census data\n",
    "final_df = df_allyears.merge(census_df, how='left', on=['city_key','state_key','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "# Function to convert to float otherwise set to NaN\n",
    "def f(x):\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "# Look at final Cleaning of data-types\n",
    "float_cols = final_df.columns.difference([\"MSA\", \"city_key\", \"state_key\",\"year\", \"largest_city\"])\n",
    "for v in float_cols:\n",
    "    try:\n",
    "        final_df[v] = final_df[v].astype(float)\n",
    "    except:\n",
    "        continue\n",
    "# Assault Rate Needs to be fixed\n",
    "# One Value is missing\n",
    "final_df.loc[final_df.rate_assault == \" \", 'rate_assault'] = np.nan\n",
    "final_df[\"rate_assault\"] = final_df[\"rate_assault\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide": true
   },
   "source": [
    "#### PUERTO RICO CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hide": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApMAAAG5CAYAAADSyb8wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkcXgAAsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x251af08e860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Find the number of years within each MSA in Puerto Rico\n",
    "pr_msa=final_df[final_df['state_key'].str.contains(\"PR\")].groupby('MSA').count().iloc[:,31]\n",
    "fig, ax = plt.subplots(1,1, figsize=(11,7))\n",
    "ax.hist(pr_msa, color='teal',alpha=0.5)\n",
    "ax.set_title('Number of years in Peurto-Rico MSA Data')\n",
    "ax.set_xlabel('Number of years')\n",
    "ax.set_ylabel('Number of MSAs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "#Exclude any PR data\n",
    "final_df = final_df.loc[~final_df['state_key'].str.contains(\"PR\"), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "#Create a join key\n",
    "final_df['join_key'] = final_df['city_key'].str.cat(final_df['state_key'],sep='-')\n",
    "#Add columns for OHE\n",
    "final_df['year_ohe'] = final_df['year']\n",
    "final_df['state_ohe'] = final_df['state_key']\n",
    "final_df['join_ohe'] = final_df['join_key']\n",
    "#One hot encode join key, state key and year\n",
    "final_df = pd.get_dummies(final_df,prefix='year',columns=['year_ohe']) #Not dropping one column since year has missing values\n",
    "final_df = pd.get_dummies(final_df,prefix=['MSA','state'],columns=['join_ohe','state_ohe'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "final_df.to_json('output/final.json')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
